{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Data Loading and Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Load and preprocess the bread sales data.\"\"\"\n",
    "    raw_df = pd.read_csv(file_path)\n",
    "    df = raw_df[[\"date\", \"filled_sold_bread\", \"day\", \n",
    "                 \"temperature_2m_mean\", \"precipitation_sum_mm\"]].copy()\n",
    "    \n",
    "    # Rename columns to match Prophet's requirements\n",
    "    df.columns = [\"ds\", \"y\", \"day\", \"temperature_2m_mean\", \"precipitation_sum_mm\"]\n",
    "    \n",
    "    # Convert date and sales\n",
    "    df.loc[:, \"ds\"] = pd.to_datetime(df[\"ds\"], format=\"%d/%m/%Y\")\n",
    "    df.loc[:, \"y\"] = pd.to_numeric(df[\"y\"])\n",
    "    \n",
    "    # Create day dummies\n",
    "    day_dummies = pd.get_dummies(df[\"day\"], prefix=\"day\")\n",
    "    df = pd.concat([df, day_dummies], axis=1)\n",
    "    \n",
    "    return df, day_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Model Configuration and Training\n",
    "\n",
    "def configure_prophet_model():\n",
    "    \"\"\"Configure Prophet model with custom parameters and seasonality.\"\"\"\n",
    "    model = Prophet(\n",
    "        changepoint_prior_scale=0.05,  # Controls flexibility of trend changes\n",
    "        changepoint_range=0.9,         # Consider trend changes up to 90% of timeline\n",
    "        seasonality_prior_scale=10.0   # Controls flexibility of seasonality\n",
    "    )\n",
    "    \n",
    "    # Add custom seasonality patterns\n",
    "    model.add_seasonality(name='weekly', period=7, fourier_order=3)\n",
    "    model.add_seasonality(name='yearly', period=365.25, fourier_order=10)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_regressors(model, day_dummies):\n",
    "    \"\"\"Add additional features (regressors) to the model.\"\"\"\n",
    "    # Add day-of-week indicators\n",
    "    for col in day_dummies.columns:\n",
    "        model.add_regressor(col)\n",
    "    \n",
    "    # Add weather-related features\n",
    "    model.add_regressor('temperature_2m_mean')\n",
    "    model.add_regressor('precipitation_sum_mm')\n",
    "\n",
    "def train_model(df, day_dummies):\n",
    "    \"\"\"Configure and train the Prophet model.\"\"\"\n",
    "    # Configure base model\n",
    "    model = configure_prophet_model()\n",
    "    \n",
    "    # Add additional features\n",
    "    add_regressors(model, day_dummies)\n",
    "    \n",
    "    # Fit the model\n",
    "    print(\"Training model...\")\n",
    "    model.fit(df)\n",
    "    print(\"Model training completed\")\n",
    "    \n",
    "    # # Save the trained model\n",
    "    # with open('prophet_model.pkl', 'wb') as f:\n",
    "    #     pickle.dump(model, f)\n",
    "    #     print(\"Model saved to prophet_model.pkl\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Model Evaluation\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"Perform cross-validation and display performance metrics.\"\"\"\n",
    "    # Perform cross-validation\n",
    "    df_cv = cross_validation(\n",
    "        model, \n",
    "        initial='365 days',\n",
    "        period='30 days',\n",
    "        horizon='30 days'\n",
    "    )\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    df_p = performance_metrics(df_cv)\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    print(df_p)\n",
    "    \n",
    "    # Plot cross-validation results\n",
    "    from prophet.plot import plot_cross_validation_metric\n",
    "    fig = plot_cross_validation_metric(df_cv, metric='rmse')\n",
    "    \n",
    "    return df_cv, df_p, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Future Predictions\n",
    "\n",
    "def prepare_future_dataframe(model, df, day_dummies, prediction_days=365):\n",
    "    \"\"\"Prepare future dataframe for predictions.\"\"\"\n",
    "    # Get last date with actual data\n",
    "    last_actual_date = df[df['y'].notna()]['ds'].max()\n",
    "    print(f\"Last date with actual sales data: {last_actual_date}\")\n",
    "    \n",
    "    # Create future dataframe\n",
    "    future = model.make_future_dataframe(periods=prediction_days)\n",
    "    prediction_end_date = last_actual_date + pd.DateOffset(days=prediction_days)\n",
    "    future = future[future['ds'] <= prediction_end_date]\n",
    "    \n",
    "    # Add features\n",
    "    # Day dummies\n",
    "    future = pd.concat([future, day_dummies.reindex(future.index, fill_value=0)], axis=1)\n",
    "    \n",
    "    # Weather features (using historical means)\n",
    "    for feature in ['temperature_2m_mean', 'precipitation_sum_mm']:\n",
    "        if feature in df.columns:\n",
    "            future[feature] = df[feature].reindex(\n",
    "                future.index, \n",
    "                fill_value=df[feature].mean()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"{feature} data missing for predictions\")\n",
    "    \n",
    "    return future, last_actual_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Visualization and Results Export\n",
    "def create_visualization(model, forecast, path):\n",
    "    \"\"\"Create basic forecast visualization\"\"\"\n",
    "    # Create the matplotlib figure\n",
    "    fig = model.plot(forecast)\n",
    "    \n",
    "    # Convert to plotly figure\n",
    "    plotly_fig = tls.mpl_to_plotly(fig)\n",
    "    \n",
    "    # Display the plotly figure\n",
    "    plot(plotly_fig, filename=path, auto_open=False)\n",
    "    print(f\"Plot saved to: {path}\")\n",
    "    \n",
    "def export_results(forecast, output_path):\n",
    "    \"\"\"Save forecast results to CSV\"\"\"\n",
    "    forecast.to_csv(output_path, index=False)\n",
    "    print(f\"Forecast saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:41:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "Seasonality has period of 365.25 days which is larger than initial window. Consider increasing initial.\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]09:41:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 11%|█         | 1/9 [00:00<00:01,  4.14it/s]09:41:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 22%|██▏       | 2/9 [00:00<00:01,  4.26it/s]09:41:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 33%|███▎      | 3/9 [00:00<00:01,  4.15it/s]09:41:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 44%|████▍     | 4/9 [00:00<00:01,  4.13it/s]09:41:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 56%|█████▌    | 5/9 [00:01<00:01,  3.65it/s]09:41:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 67%|██████▋   | 6/9 [00:01<00:00,  3.23it/s]09:41:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 78%|███████▊  | 7/9 [00:01<00:00,  3.31it/s]09:41:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:45 - cmdstanpy - INFO - Chain [1] done processing\n",
      " 89%|████████▉ | 8/9 [00:02<00:00,  3.42it/s]09:41:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:41:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date with actual sales data: 2022-09-30 00:00:00\n",
      "Plot saved to: c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\\visualizations\\forecast_plot.html\n",
      "Forecast saved to: c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\\visualizations\\forecast_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avrahamma\\AppData\\Roaming\\Python\\Python310\\site-packages\\plotly\\matplotlylib\\renderer.py:571: UserWarning:\n",
      "\n",
      "Dang! That path collection is out of this world. I totally don't know what to do with it yet! Plotly can only import path collections linked to 'data' coordinates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = r\"c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\"\n",
    "\n",
    "    # 1. Load and preprocess data\n",
    "    df, day_dummies = load_and_preprocess_data(os.path.join(base_path, \"data\", \"paris_bread_sales.csv\"))\n",
    "    \n",
    "    # 2. Configure and train model\n",
    "    model = configure_prophet_model()\n",
    "    add_regressors(model, day_dummies)\n",
    "    model.fit(df)\n",
    "    \n",
    "    # 3. Save trained model \n",
    "    with open(os.path.join(base_path, \"model\", \"prophet_model.pkl\"), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    # 4. Evaluate model\n",
    "    df_cv = cross_validation(model, initial='365 days', period='30 days', horizon='30 days')\n",
    "    df_p = performance_metrics(df_cv)\n",
    "    \n",
    "    # 5. Generate predictions\n",
    "    future, last_actual_date = prepare_future_dataframe(model, df, day_dummies)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # 6. Visualize and export results\n",
    "    create_visualization(model, forecast, os.path.join(base_path, \"visualizations\", \"forecast_plot.html\"))\n",
    "    export_results(forecast, os.path.join(base_path, \"visualizations\", \"forecast_results.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
