{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install streamlit pandas prophet plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avrahamma\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "import plotly.tools as tls\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import streamlit as st\n",
    "\n",
    "# Load the data\n",
    "raw_df = pd.read_csv(r\"c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\\paris_bread_sales - Sheet2.csv\")\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "df = raw_df[[\"date\", \"filled_sold_bread\", \"day\", \"temperature_2m_mean\", \"precipitation_sum_mm\"]].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "df.columns = [\"ds\", \"y\", \"day\", \"temperature_2m_mean\", \"precipitation_sum_mm\"]  # Rename the columns to match Prophet's requirements\n",
    "\n",
    "# Convert the date to a datetime object\n",
    "df.loc[:, \"ds\"] = pd.to_datetime(df[\"ds\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Convert the sales to a numeric object\n",
    "df.loc[:, \"y\"] = pd.to_numeric(df[\"y\"])\n",
    "\n",
    "# One-hot encode the \"day\" column\n",
    "day_dummies = pd.get_dummies(df[\"day\"], prefix=\"day\")\n",
    "df = pd.concat([df, day_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales average per day of the week:          day           y\n",
      "0     friday  526.467391\n",
      "1     monday  539.384615\n",
      "2   saturday  687.934066\n",
      "3     sunday  916.626374\n",
      "4   thursday  503.098901\n",
      "5    tuesday  475.120879\n",
      "6  wednesday  461.428571\n",
      "Correlation between temperature and sales: 0.4983014746258398\n",
      "Correlation between precipitation and sales: -0.06072179712236452\n",
      "Average sales on extreme cold days: 355.6296296296296\n",
      "Average sales on normal days: 597.2831423895253\n",
      "T-statistic: nan, P-value: nan\n",
      "There is no statistically significant difference in sales on extreme cold days.\n",
      "Average sales on extreme rainy days: 387.6666666666667\n",
      "Average sales on normal days: 587.9984251968503\n",
      "T-statistic: nan, P-value: nan\n",
      "There is no statistically significant difference in sales on extreme rainy days.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# feeling the data\n",
    "\n",
    "# calculate and print the average of bread sales for each day of the week\n",
    "# Ensure the \"y\" column contains only numeric data\n",
    "df[\"y\"] = pd.to_numeric(df[\"y\"], errors='coerce')\n",
    "\n",
    "# Calculate and print the average of bread sales for each day of the week\n",
    "day_avg = df.groupby(\"day\")[\"y\"].mean().reset_index()\n",
    "day_avg.columns = [\"day\", \"y\"]\n",
    "print(\"Sales average per day of the week:\", day_avg)\n",
    "\n",
    "# understanding the relationship between the sales and the temperature\n",
    "# Ensure the \"temperature_2m_mean\" column contains only numeric data\n",
    "df[\"temperature_2m_mean\"] = pd.to_numeric(df[\"temperature_2m_mean\"], errors='coerce')\n",
    "\n",
    "# Calculate and print the correlation between the sales and the temperature\n",
    "temperature_corr = df[\"y\"].corr(df[\"temperature_2m_mean\"])\n",
    "print(\"Correlation between temperature and sales:\", temperature_corr)\n",
    "\n",
    "# Ensure the \"precipitation_sum_mm\" column contains only numeric data\n",
    "df[\"precipitation_sum_mm\"] = pd.to_numeric(df[\"precipitation_sum_mm\"], errors='coerce')\n",
    "\n",
    "# Calculate and print the correlation between the sales and the precipitation\n",
    "precipitation_corr = df[\"y\"].corr(df[\"precipitation_sum_mm\"])\n",
    "print(\"Correlation between precipitation and sales:\", precipitation_corr)\n",
    "\n",
    "# check how sales are affected by extreme cold days\n",
    "# Step 1: Define extreme cold days (bottom 5% of temperature)\n",
    "cold_threshold = df['temperature_2m_mean'].quantile(0.05)  # Get the 5th percentile value\n",
    "extreme_cold_days = df[df['temperature_2m_mean'] <= cold_threshold]  # Filter for extreme cold days\n",
    "normal_days = df[df['temperature_2m_mean'] > cold_threshold]  # Filter for the rest of the days\n",
    "\n",
    "# Step 2: Calculate average sales for both groups\n",
    "avg_sales_cold = extreme_cold_days['y'].mean()\n",
    "avg_sales_normal = normal_days['y'].mean()\n",
    "\n",
    "print(f\"Average sales on extreme cold days: {avg_sales_cold}\")\n",
    "print(f\"Average sales on normal days: {avg_sales_normal}\")\n",
    "\n",
    "# Step 3: Compare the averages with a t-test (Optional)\n",
    "# Null hypothesis: No difference in sales between extreme cold and normal days\n",
    "t_stat, p_value = ttest_ind(extreme_cold_days['y'], normal_days['y'], equal_var=False)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference in sales on extreme cold days.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference in sales on extreme cold days.\")\n",
    "\n",
    "# check how sales are affected by extreme rainy days\n",
    "# Step 1: Define extreme rainy days (top 5% of precipitation)\n",
    "rainy_threshold = df['precipitation_sum_mm'].quantile(0.99)  # Get the 95th percentile value\n",
    "\n",
    "extreme_rainy_days = df[df['precipitation_sum_mm'] >= rainy_threshold]  # Filter for extreme rainy days\n",
    "normal_days = df[df['precipitation_sum_mm'] < rainy_threshold]  # Filter for the rest of the days\n",
    "\n",
    "# Step 2: Calculate average sales for both groups\n",
    "avg_sales_rainy = extreme_rainy_days['y'].mean()\n",
    "avg_sales_normal = normal_days['y'].mean()\n",
    "\n",
    "print(f\"Average sales on extreme rainy days: {avg_sales_rainy}\")\n",
    "print(f\"Average sales on normal days: {avg_sales_normal}\")\n",
    "\n",
    "# Step 3: Compare the averages with a t-test (Optional)\n",
    "# Null hypothesis: No difference in sales between extreme rainy and normal days\n",
    "t_stat, p_value = ttest_ind(extreme_rainy_days['y'], normal_days['y'], equal_var=False)\n",
    "\n",
    "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference in sales on extreme rainy days.\")\n",
    "else:\n",
    "    print(\"There is no statistically significant difference in sales on extreme rainy days.\")\n",
    "\n",
    "# export the data as csv\n",
    "# df.to_csv(r\"c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\\paris_bread_sales_prophet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last date with actual sales data: 2022-09-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:39:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# First, identify the last date with actual sales data\n",
    "last_actual_date = df[df['y'].notna()]['ds'].max()\n",
    "print(f\"Last date with actual sales data: {last_actual_date}\")\n",
    "\n",
    "# Split the data for training - use only data up to the last actual date\n",
    "train_df = df[df['ds'] <= last_actual_date].copy()\n",
    "\n",
    "# Initialize and train the model on training data only\n",
    "model = Prophet()\n",
    "# Add the regressors\n",
    "for col in day_dummies.columns:\n",
    "    model.add_regressor(col)\n",
    "model.add_regressor('temperature_2m_mean')\n",
    "model.add_regressor('precipitation_sum_mm')\n",
    "\n",
    "# Add custom seasonality\n",
    "model.add_seasonality(name='weekly', period=7, fourier_order=3)\n",
    "model.add_seasonality(name='yearly', period=365.25, fourier_order=10)\n",
    "\n",
    "# Train the model\n",
    "model.fit(df)\n",
    "\n",
    "# Save the model\n",
    "with open('prophet_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Create future dataframe that goes exactly one year ahead from the last actual date\n",
    "future = model.make_future_dataframe(periods=365)\n",
    "prediction_end_date = last_actual_date + pd.DateOffset(days=365)\n",
    "future = future[future['ds'] <= prediction_end_date]\n",
    "\n",
    "# Add the regressors to the future DataFrame\n",
    "# Add day dummies to the future dataframe\n",
    "future = pd.concat([future, day_dummies.reindex(future.index, fill_value=0)], axis=1)\n",
    "\n",
    "# Add temperature data to the future dataframe\n",
    "if 'temperature_2m_mean' in df.columns:\n",
    "    future['temperature_2m_mean'] = df['temperature_2m_mean'].reindex(future.index, fill_value=df['temperature_2m_mean'].mean())\n",
    "else:\n",
    "    raise ValueError(\"Temperature data is missing for future predictions. Please provide the temperature data.\")\n",
    "\n",
    "# Add precipitation data to the future dataframe\n",
    "if 'precipitation_sum_mm' in df.columns:\n",
    "    future['precipitation_sum_mm'] = df['precipitation_sum_mm'].reindex(future.index, fill_value=df['precipitation_sum_mm'].mean())\n",
    "else:\n",
    "    raise ValueError(\"Precipitation data is missing for future predictions. Please provide the precipitation data.\")\n",
    "\n",
    "# Make predictions\n",
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avrahamma\\AppData\\Roaming\\Python\\Python310\\site-packages\\plotly\\matplotlylib\\renderer.py:571: UserWarning:\n",
      "\n",
      "Dang! That path collection is out of this world. I totally don't know what to do with it yet! Plotly can only import path collections linked to 'data' coordinates\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ds       trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
      "0 2021-01-01  557.058870  226.530040  582.662648   557.058870   557.058870   \n",
      "1 2021-01-02  557.196089  379.915668  725.570451   557.196089   557.196089   \n",
      "2 2021-01-03  557.333309  611.877114  954.203684   557.333309   557.333309   \n",
      "3 2021-01-04  557.470528  223.294497  566.576466   557.470528   557.470528   \n",
      "4 2021-01-05  557.607747  147.558526  493.754539   557.607747   557.607747   \n",
      "\n",
      "   additive_terms  additive_terms_lower  additive_terms_upper  day_friday  \\\n",
      "0     -155.313577           -155.313577           -155.313577   20.986016   \n",
      "1       -3.236207             -3.236207             -3.236207    0.000000   \n",
      "2      221.299412            221.299412            221.299412    0.000000   \n",
      "3     -164.640155           -164.640155           -164.640155    0.000000   \n",
      "4     -237.577698           -237.577698           -237.577698    0.000000   \n",
      "\n",
      "   ...      weekly  weekly_lower  weekly_upper      yearly  yearly_lower  \\\n",
      "0  ...  -45.148369    -45.148369    -45.148369  -91.551193    -91.551193   \n",
      "1  ...   78.791125     78.791125     78.791125  -99.908506    -99.908506   \n",
      "2  ...  256.418568    256.418568    256.418568 -108.376929   -108.376929   \n",
      "3  ...  -37.399802    -37.399802    -37.399802 -116.894443   -116.894443   \n",
      "4  ...  -87.123582    -87.123582    -87.123582 -125.409801   -125.409801   \n",
      "\n",
      "   yearly_upper  multiplicative_terms  multiplicative_terms_lower  \\\n",
      "0    -91.551193                   0.0                         0.0   \n",
      "1    -99.908506                   0.0                         0.0   \n",
      "2   -108.376929                   0.0                         0.0   \n",
      "3   -116.894443                   0.0                         0.0   \n",
      "4   -125.409801                   0.0                         0.0   \n",
      "\n",
      "   multiplicative_terms_upper        yhat  \n",
      "0                         0.0  401.745293  \n",
      "1                         0.0  553.959883  \n",
      "2                         0.0  778.632721  \n",
      "3                         0.0  392.830373  \n",
      "4                         0.0  320.030050  \n",
      "\n",
      "[5 rows x 49 columns]\n",
      "             ds       trend  yhat_lower  yhat_upper  trend_lower  trend_upper  \\\n",
      "998  2023-09-26  538.777060  235.930171  561.640851   512.983497   565.359014   \n",
      "999  2023-09-27  538.825740  212.906810  556.385631   512.807536   565.465452   \n",
      "1000 2023-09-28  538.874419  243.562963  596.079181   512.751870   565.572266   \n",
      "1001 2023-09-29  538.923099  272.024461  618.003880   512.731992   565.757491   \n",
      "1002 2023-09-30  538.971778  408.207305  757.163656   512.712104   565.959973   \n",
      "\n",
      "      additive_terms  additive_terms_lower  additive_terms_upper  day_friday  \\\n",
      "998      -144.689403           -144.689403           -144.689403    0.000000   \n",
      "999      -156.244685           -156.244685           -156.244685    0.000000   \n",
      "1000     -118.833060           -118.833060           -118.833060    0.000000   \n",
      "1001      -95.898275            -95.898275            -95.898275   20.986016   \n",
      "1002       46.574851             46.574851             46.574851    0.000000   \n",
      "\n",
      "      ...     weekly  weekly_lower  weekly_upper      yearly  yearly_lower  \\\n",
      "998   ... -87.123582    -87.123582    -87.123582  -86.216090    -86.216090   \n",
      "999   ... -98.691093    -98.691093    -98.691093  -87.722110    -87.722110   \n",
      "1000  ... -66.846848    -66.846848    -66.846848  -90.564020    -90.564020   \n",
      "1001  ... -45.148369    -45.148369    -45.148369  -94.691134    -94.691134   \n",
      "1002  ...  78.791125     78.791125     78.791125 -100.002329   -100.002329   \n",
      "\n",
      "      yearly_upper  multiplicative_terms  multiplicative_terms_lower  \\\n",
      "998     -86.216090                   0.0                         0.0   \n",
      "999     -87.722110                   0.0                         0.0   \n",
      "1000    -90.564020                   0.0                         0.0   \n",
      "1001    -94.691134                   0.0                         0.0   \n",
      "1002   -100.002329                   0.0                         0.0   \n",
      "\n",
      "      multiplicative_terms_upper        yhat  \n",
      "998                          0.0  394.087657  \n",
      "999                          0.0  382.581054  \n",
      "1000                         0.0  420.041359  \n",
      "1001                         0.0  443.024824  \n",
      "1002                         0.0  585.546629  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Plot the forecast\n",
    "fig = model.plot(forecast)\n",
    "\n",
    "# Convert the Matplotlib figure to a Plotly figure\n",
    "plotly_fig = tls.mpl_to_plotly(fig)\n",
    "\n",
    "# Display the Plotly figure\n",
    "plot(plotly_fig)\n",
    "\n",
    "print(forecast.head())\n",
    "print(forecast.tail())\n",
    "\n",
    "# Save the forecast to a CSV file\n",
    "# forecast_path = r\"c:\\Users\\avrahamma\\Documents\\School\\AI_for_social_good\\prophet_forecast.csv\"\n",
    "# forecast.to_csv(forecast_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def load_model():\n",
    "    # Load the trained Prophet model\n",
    "    model = Prophet()\n",
    "    # Add your regressors here as in your notebook\n",
    "    model.add_regressor('temperature_2m_mean')\n",
    "    model.add_regressor('precipitation_sum_mm')\n",
    "    for day in ['day_friday', 'day_monday', 'day_saturday', \n",
    "                'day_sunday', 'day_thursday', 'day_tuesday', 'day_wednesday']:\n",
    "        model.add_regressor(day)\n",
    "    return model\n",
    "\n",
    "def create_future_df(date, temperature, precipitation):\n",
    "    # Create a DataFrame for prediction\n",
    "    future = pd.DataFrame({\n",
    "        'ds': [date],\n",
    "        'temperature_2m_mean': [temperature],\n",
    "        'precipitation_sum_mm': [precipitation]\n",
    "    })\n",
    "    \n",
    "    # Add day dummies\n",
    "    day_name = date.strftime('%A').lower()\n",
    "    for day in ['friday', 'monday', 'saturday', 'sunday', 'thursday', 'tuesday', 'wednesday']:\n",
    "        future[f'day_{day}'] = 1 if day == day_name else 0\n",
    "    \n",
    "    return future\n",
    "\n",
    "def main():\n",
    "    st.title(\"ðŸ¥– Bread Sales Predictor\")\n",
    "    \n",
    "    # Sidebar for inputs\n",
    "    st.sidebar.header(\"Input Parameters\")\n",
    "    \n",
    "    # Date selector (defaulting to tomorrow)\n",
    "    tomorrow = datetime.date.today() + datetime.timedelta(days=1)\n",
    "    date = st.sidebar.date_input(\"Select Date\", value=tomorrow)\n",
    "    \n",
    "    # Temperature input\n",
    "    temperature = st.sidebar.slider(\n",
    "        \"Temperature (Â°C)\",\n",
    "        min_value=-10.0,\n",
    "        max_value=40.0,\n",
    "        value=20.0,\n",
    "        step=0.5\n",
    "    )\n",
    "    \n",
    "    # Precipitation input\n",
    "    precipitation = st.sidebar.slider(\n",
    "        \"Precipitation (mm)\",\n",
    "        min_value=0.0,\n",
    "        max_value=50.0,\n",
    "        value=0.0,\n",
    "        step=0.5\n",
    "    )\n",
    "    \n",
    "    # Load model\n",
    "    try:\n",
    "        model = load_model()\n",
    "        \n",
    "        # Create future DataFrame\n",
    "        future = create_future_df(pd.to_datetime(date), temperature, precipitation)\n",
    "        \n",
    "        # Make prediction\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        # Main content\n",
    "        st.header(\"Prediction Results\")\n",
    "        \n",
    "        # Display the predicted amount with confidence interval\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        \n",
    "        with col1:\n",
    "            st.metric(\n",
    "                label=\"Predicted Bread Loaves\",\n",
    "                value=f\"{int(forecast['yhat'].iloc[0])}\",\n",
    "                delta=None\n",
    "            )\n",
    "        \n",
    "        with col2:\n",
    "            st.metric(\n",
    "                label=\"Lower Bound\",\n",
    "                value=f\"{int(forecast['yhat_lower'].iloc[0])}\",\n",
    "                delta=None\n",
    "            )\n",
    "            \n",
    "        with col3:\n",
    "            st.metric(\n",
    "                label=\"Upper Bound\",\n",
    "                value=f\"{int(forecast['yhat_upper'].iloc[0])}\",\n",
    "                delta=None\n",
    "            )\n",
    "        \n",
    "        # Display additional information\n",
    "        st.subheader(\"Prediction Details\")\n",
    "        info_col1, info_col2 = st.columns(2)\n",
    "        \n",
    "        with info_col1:\n",
    "            st.info(f\"Date: {date.strftime('%A, %B %d, %Y')}\")\n",
    "            st.info(f\"Temperature: {temperature}Â°C\")\n",
    "            \n",
    "        with info_col2:\n",
    "            st.info(f\"Precipitation: {precipitation}mm\")\n",
    "            confidence_range = f\"Â±{int((forecast['yhat_upper'].iloc[0] - forecast['yhat_lower'].iloc[0])/2)} loaves\"\n",
    "            st.info(f\"Confidence Range: {confidence_range}\")\n",
    "        \n",
    "        # Add historical context\n",
    "        st.subheader(\"Historical Context\")\n",
    "        st.write(f\"This prediction is based on historical sales data and takes into account:\")\n",
    "        st.write(\"- Day of the week patterns\")\n",
    "        st.write(\"- Temperature effects\")\n",
    "        st.write(\"- Precipitation impacts\")\n",
    "        st.write(\"- Seasonal trends\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {str(e)}\")\n",
    "        st.write(\"Please ensure the model file is properly loaded and all required dependencies are installed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
